{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Recipe: Prompt Type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "model_ids = ['model_a'] # TODO: Update to models for prompt type analysis\n",
    "dataset_names = [\n",
    "    'evaluation_library.data.real_datasets_balanced.COCO15K',\n",
    "    'evaluation_library.data.real_datasets_balanced.ImageNetValidation15K',\n",
    "    'evaluation_library.data.real_datasets_balanced.CC12MValidation15K',\n",
    "    'evaluation_library.data.real_datasets_balanced.GeoDE15K']\n",
    "cfg_scale = 7.5\n",
    "output_path = '.'\n",
    "\n",
    "for model_id in model_ids:\n",
    "    for dataset_name in dataset_names:\n",
    "        command = (\n",
    "                f\"python -m evaluation_library.generate \"\n",
    "                f\"--batch_size 4 \"\n",
    "                f\"--model_id {model_id} \"\n",
    "                f\"--cfg_scale {cfg_scale} \"\n",
    "                f\"--dataset_name {dataset_name} \"\n",
    "                f\"--output_path {output_path}\"\n",
    "            )\n",
    "\n",
    "        subprocess.call(command.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "model_ids = ['model_a'] # TODO: Update to models for prompt type analysis\n",
    "dataset_names = [\n",
    "    'evaluation_library.data.real_datasets_balanced.COCO15K',\n",
    "    'evaluation_library.data.real_datasets_balanced.ImageNetValidation15K',\n",
    "    'evaluation_library.data.real_datasets_balanced.CC12MValidation15K',\n",
    "    'evaluation_library.data.real_datasets_balanced.GeoDE15K']\n",
    "cfg_scale = 7.5\n",
    "output_path = '.'\n",
    "\n",
    "for model_id in model_ids:\n",
    "    for dataset_name in dataset_names:\n",
    "        image_path = f\"{output_path}/{model_id.replace('/', '--')}__{dataset_name}__cfg{cfg_scale}\"\n",
    "        command = (\n",
    "                f\"python3 -m evaluation_library.launcher_with_accelerate \"\n",
    "                f\"--ngpus 8 \"\n",
    "                f\"--nodes 1 \"\n",
    "                f\"--partition learnlab \"  ## TODO: Customize for your set-up\n",
    "                f\"--name test \"\n",
    "                f\"--seed 0 \"\n",
    "                f\"--logdir {output_path}/evals \"\n",
    "                f\"--generated_images_path {image_path} \"\n",
    "                f\"--model_id {model_id} \"\n",
    "                f\"--cfg_scale {cfg_scale} \"\n",
    "                f\"--eval_dataset_name {dataset_name} \"\n",
    "                f\"--marginal_metrics fid_torchmetrics,prdc \"\n",
    "                f\"--conditional_metrics clipscore\"\n",
    "            )\n",
    "\n",
    "        subprocess.call(command.split(\" \"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m evaluation_library.visualizations.datasets --csv_path ./evals/results.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e78aa4dbc4e2a8f70228fddc6869bfc64d2b27902baad9914f2f74303c656e65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Exercise: Tradeoffs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "model_ids = ['model_a'] # TODO: Update to models for trade-offs sweep\n",
    "dataset_names = ['coco_txt_dataset'] \n",
    "cfg_scale = 7.5\n",
    "output_path = '.'\n",
    "\n",
    "for model_id in model_ids:\n",
    "    for dataset_name in dataset_names:\n",
    "        command = (\n",
    "                f\"python -m evaluation_library.generate \"\n",
    "                f\"--batch_size 4 \"\n",
    "                f\"--model_id {model_id} \"\n",
    "                f\"--cfg_scale {cfg_scale} \"\n",
    "                f\"--dataset_name {dataset_name} \"\n",
    "                f\"--output_path {output_path}\"\n",
    "            )\n",
    "\n",
    "        subprocess.call(command.split(\" \"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "model_ids = ['model_a'] # TODO: Update to models for trade-offs sweep\n",
    "dataset_names = ['coco_txt_dataset'] \n",
    "cfg_scale = 7.5\n",
    "output_path = '.'\n",
    "\n",
    "for model_id in model_ids:\n",
    "    for dataset_name in dataset_names:\n",
    "        image_path = f\"{output_path}/{model_id}__{dataset_name}__cfg{cfg_scale}\"\n",
    "        command = (\n",
    "                f\"python3 -m evaluation_library.launcher_with_accelerate \"\n",
    "                f\"--ngpus 8 \"\n",
    "                f\"--nodes 1 \"\n",
    "                f\"--partition learnlab \"  ## TODO: Customize for your set-up\n",
    "                f\"--name evaluate \"\n",
    "                f\"--seed 0 \"\n",
    "                f\"--logdir {output_path}/evals \"\n",
    "                f\"--generated_images_path {image_path} \"\n",
    "                f\"--model_id {model_id} \"\n",
    "                f\"--cfg_scale {cfg_scale} \"\n",
    "                f\"--eval_dataset_name {dataset_name} \"\n",
    "                f\"--marginal_metrics fid_torchmetrics,prdc \"\n",
    "                f\"--conditional_metrics clipscore\"\n",
    "        )\n",
    "\n",
    "        subprocess.call(command.split(\" \"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m evaluation_library.visualizations.pareto_fronts --csv_path evals/results.csv --metrics_for_three_axis precision coverage clipscore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e78aa4dbc4e2a8f70228fddc6869bfc64d2b27902baad9914f2f74303c656e65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
